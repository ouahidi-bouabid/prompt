
spring.application.name=prompt-eng-springai
spring.ai.openai.api-key="${OPENAI_API_KEY}"
# le modele openai est enabled
spring.ai.openai.chat.enabled=true
# Le modele
spring.ai.openai.chat.options.model=gpt-4o

# ollama

#spring.ai.ollama.chat.model=true
#spring.ai.ollama.chat.options.model=lama 3-8b
#spring.ai.ollama.

#Paramètres si on veut

# Max de tokens ppur la reponse
#spring.ai.openai.chat.options.max-tokens=400

#Plus c'est proche de 1 plus le LLM va utilser plus de tokens pour générer la réponse
#spring.ai.openai.chat.options.top-p=1

#Plus proche de 1 moins de chance que les tokens sont répétés
#spring.ai.openai.chat.options.frequency-penalty=1

#Temperature plus c'est proche de 0 plus la réponse est precise
#spring.ai.openai.chat.options.temperature=0.7
server.port=7071

